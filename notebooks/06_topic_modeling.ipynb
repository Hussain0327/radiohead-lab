{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling (quick LDA sketch)\n",
    "\n",
    "Rough LDA on the Kaggle lyrics export to surface dominant terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def find_root():\n",
    "    here = Path.cwd()\n",
    "    for p in [here, *here.parents]:\n",
    "        candidate = p / 'data' / 'exports' / 'radiohead_complete.json'\n",
    "        if candidate.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError('radiohead_complete.json not found; run src/processing/ingest_csv.py')\n",
    "\n",
    "root = find_root()\n",
    "data_path = root / 'data' / 'exports' / 'radiohead_complete.json'\n",
    "data = json.loads(data_path.read_text())\n",
    "print(f\"Loaded {len(data)} tracks from {data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", max_features=2000, min_df=2)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42, learning_method=\"online\")\n",
    "lda.fit(X)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def top_words(component, n=10):\n",
    "    indices = component.argsort()[-n:][::-1]\n",
    "    return [feature_names[i] for i in indices]\n",
    "\n",
    "topics = [top_words(comp) for comp in lda.components_]\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Album-topic mix\n",
    "import numpy as np\n",
    "\n",
    "doc_topic = lda.transform(X)\n",
    "albums = [row[\"album_name\"] for row in data]\n",
    "album_ids = {a: i for i, a in enumerate(sorted(set(albums)))}\n",
    "album_topic = np.zeros((len(album_ids), doc_topic.shape[1]))\n",
    "\n",
    "for doc_idx, album in enumerate(albums):\n",
    "    album_topic[album_ids[album]] += doc_topic[doc_idx]\n",
    "\n",
    "album_topic = album_topic / album_topic.sum(axis=1, keepdims=True)\n",
    "album_names_sorted = sorted(album_ids.keys())\n",
    "\n",
    "summary = []\n",
    "for i, album in enumerate(album_names_sorted):\n",
    "    top_topic = album_topic[i].argmax()\n",
    "    summary.append({\"album\": album, \"top_topic\": int(top_topic), \"weight\": round(album_topic[i][top_topic], 3)})\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}